import sys
import cv2
import numpy as np
import tensorflow as tf
import mediapipe as mp
from PyQt6.QtWidgets import QApplication, QWidget, QLabel, QVBoxLayout, QHBoxLayout, QPushButton
from PyQt6.QtGui import QImage, QPixmap
from PyQt6.QtCore import QTimer, Qt

# âœ… ëª¨ë¸ ë¡œë“œ
model = tf.keras.models.load_model("./model/Sign_ED_best.keras")

# âœ… ìˆ˜ì–´ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸
# ì œìŠ¤ì²˜ ì •ì˜
ACTIONS = [
        'ì•ˆë…•,ì•ˆë¶€', 'ì‹¤ìˆ˜', 'ì‚´ë‹¤,ì‚¶,ìƒí™œ', 'ì·¨ë¯¸',
        'ì•„ë¹ ,ë¶€,ë¶€ì¹œ,ì•„ë¹„,ì•„ë²„ì§€', 'ê±´ê°•,ê¸°ë ¥,ê°•ê±´í•˜ë‹¤,íŠ¼íŠ¼í•˜ë‹¤', 'ì‰¬ë‹¤,íœ´ê°€,íœ´ê²Œ,íœ´ì‹,íœ´ì–‘',
        'ê³ ëª¨', 'ë‹¤ë‹ˆë‹¤', 'ì£½ë‹¤,ëŒì•„ê°€ë‹¤,ì‚¬ê±°,ì‚¬ë§,ì„œê±°,ìˆ¨ì§€ë‹¤,ì£½ìŒ,ì„ì¢…', 'ë‚¨í¸,ë°°ìš°ì,ì„œë°©',
        'ëª¸ì‚´', 'ê²°í˜¼,í˜¼ì¸,í™”í˜¼', 'ë…¸ë˜,ìŒì•…,ê°€ìš”', 'ë™ìƒ', 'ëª¨ì(ê´€ê³„)', 'ì‹ ê¸°ë¡'
    ]

# âœ… MediaPipe Hands ì´ˆê¸°í™”
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils

class SignLanguageTestApp(QWidget):
    def __init__(self):
        super().__init__()
        
        # UI ì„¤ì •
        self.setWindowTitle("ìˆ˜ì–´ í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
        self.setStyleSheet("""
            QWidget {
                background-color: #eeeael;
            }
            QLabel {
                color: #368f5f;
                font-family: 'Times New Roman';
            }
            QPushButton {
                background-color: #368f5f;
                color: white;
                padding: 15px;
                border-radius: 5px;
                font-size: 18px;
                min-width: 150px;
            }
            QPushButton:hover {
                background-color: #2d7a4f;
            }
        """)
        self.showFullScreen()

        # ì´ˆê¸°í™”
        self.current_word_index = 0
        self.sequence = []
        
        # ìƒë‹¨ ì œëª©
        self.title_label = QLabel("âœ¨ ìˆ˜ì–´ í…ŒìŠ¤íŠ¸ ëª¨ë“œ âœ¨", self)
        self.title_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.title_label.setStyleSheet("font-size: 45px; font-weight: bold;")

        # í˜„ì¬ ë‹¨ì–´ í‘œì‹œ
        self.current_word_label = QLabel("", self)
        self.current_word_label.setAlignment(Qt.AlignmentFlag.AlignLeft)
        self.current_word_label.setStyleSheet("font-size: 35px; font-weight: bold; margin: 20px 0;")

        # ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ
        self.prediction_label = QLabel("", self)
        self.prediction_label.setStyleSheet("font-size: 30px;")

        # ì›¹ìº  í™”ë©´
        self.video_label = QLabel(self)
        self.video_label.setFixedSize(640, 480)
        self.video_label.setStyleSheet("border: 3px solid #368f5f; background-color: white;")

        # ì´ì „/ë‹¤ìŒ ë²„íŠ¼
        self.prev_button = QPushButton("ì´ì „ ë‹¨ì–´ (â†)", self)
        self.next_button = QPushButton("ë‹¤ìŒ ë‹¨ì–´ (â†’)", self)
        
        # ë²„íŠ¼ ê¸°ëŠ¥ ì—°ê²°
        self.prev_button.clicked.connect(self.previous_word)
        self.next_button.clicked.connect(self.next_word)

        # ë ˆì´ì•„ì›ƒ ì„¤ì •
        main_layout = QVBoxLayout()
        main_layout.addSpacing(20)
        main_layout.addWidget(self.title_label)
        main_layout.addSpacing(20)
        
        # ì •ë³´ í‘œì‹œ ì˜ì—­
        info_layout = QVBoxLayout()
        info_layout.addWidget(self.current_word_label)
        info_layout.addWidget(self.prediction_label)
        info_layout.addStretch()
        
        # ì¤‘ì•™ ë ˆì´ì•„ì›ƒ (ì •ë³´ + ì›¹ìº )
        center_layout = QHBoxLayout()
        center_layout.addLayout(info_layout)
        center_layout.addWidget(self.video_label, alignment=Qt.AlignmentFlag.AlignCenter)
        main_layout.addLayout(center_layout)
        
        # ë²„íŠ¼ ë ˆì´ì•„ì›ƒ
        button_layout = QHBoxLayout()
        button_layout.addWidget(self.prev_button)
        button_layout.addWidget(self.next_button)
        main_layout.addLayout(button_layout)
        main_layout.addSpacing(30)

        self.setLayout(main_layout)

        # ì›¹ìº  ì´ˆê¸°í™” ë° ì‹œì‘
        self.cap = cv2.VideoCapture(0)
        self.timer = QTimer()
        self.timer.timeout.connect(self.update_frame)
        self.timer.start(30)

        # ì²« ë²ˆì§¸ ë‹¨ì–´ í‘œì‹œ
        self.update_current_word()

    def keyPressEvent(self, event):
        """í‚¤ë³´ë“œ ë‹¨ì¶•í‚¤ ì²˜ë¦¬"""
        if event.key() == Qt.Key.Key_Q:
            self.close()
        elif event.key() == Qt.Key.Key_Left:
            self.previous_word()
        elif event.key() == Qt.Key.Key_Right:
            self.next_word()

    def update_current_word(self):
        """í˜„ì¬ í…ŒìŠ¤íŠ¸ ì¤‘ì¸ ë‹¨ì–´ ì—…ë°ì´íŠ¸"""
        current_word = ACTIONS[self.current_word_index]
        total_words = len(ACTIONS)
        self.current_word_label.setText(
            f"ğŸ“ í˜„ì¬ ë‹¨ì–´ ({self.current_word_index + 1}/{total_words}):\n{current_word}"
        )
        self.prediction_label.setText("ìˆ˜ì–´ë¥¼ ì‹œì‘í•´ì£¼ì„¸ìš”! ğŸ–")

    def previous_word(self):
        """ì´ì „ ë‹¨ì–´ë¡œ ì´ë™"""
        if self.current_word_index > 0:
            self.current_word_index -= 1
            self.update_current_word()
            self.sequence = []

    def next_word(self):
        """ë‹¤ìŒ ë‹¨ì–´ë¡œ ì´ë™"""
        if self.current_word_index < len(ACTIONS) - 1:
            self.current_word_index += 1
            self.update_current_word()
            self.sequence = []
        
    def update_frame(self):
        """ì›¹ìº  í”„ë ˆì„ ì—…ë°ì´íŠ¸ ë° ì˜ˆì¸¡"""
        if self.cap is None:
            return

        ret, frame = self.cap.read()
        if not ret:
            return

        # ì›ë³¸ í”„ë ˆì„ì„ ì¸ì‹ì— ì‚¬ìš©
        frame_for_detection = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # MediaPipe ì† ì¸ì‹ (ì›ë³¸ í”„ë ˆì„ ì‚¬ìš©)
        with mp_hands.Hands(
            min_detection_confidence=0.7,
            min_tracking_confidence=0.7
        ) as hands:
            results = hands.process(frame_for_detection)

        # ëœë“œë§ˆí¬ ë°ì´í„° ì €ì¥
        landmarks = np.zeros((63,), dtype=np.float32)
        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                mp_drawing.draw_landmarks(frame_for_detection, hand_landmarks, mp_hands.HAND_CONNECTIONS)
                landmarks = np.array([[lm.x, lm.y, lm.z] for lm in hand_landmarks.landmark]).flatten()

        # ì‹œí€€ìŠ¤ ë°ì´í„° ì €ì¥
        self.sequence.append(landmarks)
        if len(self.sequence) > 30:
            self.sequence = self.sequence[1:]

        # ì˜ˆì¸¡ ì‹¤í–‰
        if len(self.sequence) == 30:
            input_data = np.expand_dims(self.sequence, axis=0)
            predictions = model.predict(input_data)[0]
            max_index = np.argmax(predictions)
            predicted_action = ACTIONS[max_index]
            confidence = predictions[max_index] * 100

            # í˜„ì¬ ë‹¨ì–´ì™€ ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ
            current_word = ACTIONS[self.current_word_index]
            if predicted_action == current_word and confidence > 80:
                result_color = "#2d7a4f"  # ì´ˆë¡ìƒ‰ (ì„±ê³µ)
                result_text = "âœ… ì •í™•íˆ ì¸ì‹ë˜ì—ˆìŠµë‹ˆë‹¤!"
            else:
                result_color = "#cc7fb5"  # ë¹¨ê°„ìƒ‰ (ì‹¤íŒ¨)
                result_text = "âŒ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”"

            # ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ
            self.prediction_label.setStyleSheet(f"font-size: 30px; color: {result_color};")
            self.prediction_label.setText(
                f"ğŸ¯ ì˜ˆì¸¡ëœ ë‹¨ì–´: {predicted_action}\n"
                f"ì •í™•ë„: {confidence:.1f}%\n"
                f"{result_text}"
            )

        # ë””ìŠ¤í”Œë ˆì´ìš© í”„ë ˆì„ ì¢Œìš° ë°˜ì „
        display_frame = cv2.flip(frame_for_detection, 1)

        # OpenCV â†’ PyQt ë³€í™˜ ë° í™”ë©´ ì¶œë ¥ (ë°˜ì „ëœ í”„ë ˆì„ ì‚¬ìš©)
        h, w, ch = display_frame.shape
        bytes_per_line = ch * w
        q_image = QImage(display_frame.data, w, h, bytes_per_line, QImage.Format.Format_RGB888)
        self.video_label.setPixmap(QPixmap.fromImage(q_image))

    def closeEvent(self, event):
        """ì•± ì¢…ë£Œ ì‹œ ì •ë¦¬"""
        self.timer.stop()
        if self.cap is not None:
            self.cap.release()
        event.accept()

if __name__ == "__main__":
    app = QApplication(sys.argv)
    window = SignLanguageTestApp()
    window.show()
    sys.exit(app.exec())