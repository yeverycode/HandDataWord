import cv2
import numpy as np
import mediapipe as mp
import os
import time

# MediaPipe ì´ˆê¸°í™”
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils

# ì €ì¥ ê²½ë¡œ
dataset_path = "./Sign_ED/test/testdata"
os.makedirs(dataset_path, exist_ok=True)

# ì €ì¥í•  ì œìŠ¤ì²˜ ë¼ë²¨ ëª©ë¡ ì…ë ¥ë°›ê¸°
manual_labels = input("ğŸ‘‰ ì €ì¥í•  ë¼ë²¨ì„ ì…ë ¥í•˜ì„¸ìš” (ì‰¼í‘œë¡œ êµ¬ë¶„, ì˜ˆ: ã„±, ã„², ã„·, ã…˜, ã…™): ").split(',')
manual_labels = [label.strip() for label in manual_labels]  # ê³µë°± ì œê±°

# ìŒììŒ/ì´ì¤‘ëª¨ìŒ ì²˜ë¦¬ ê·œì¹™
double_consonants = {'ã„²': ['ã„±', 'ã„±'], 'ã„¸': ['ã„·', 'ã„·'], 'ã…ƒ': ['ã…‚', 'ã…‚'], 'ã…†': ['ã……', 'ã……'], 'ã…‰': ['ã…ˆ', 'ã…ˆ']}
double_vowels = {'ã…˜': ['ã…—', 'ã…'], 'ã…™': ['ã…—', 'ã…'], 'ã…': ['ã…œ', 'ã…“'], 'ã…': ['ã…œ', 'ã…”']}

# ì›¹ìº  ì—´ê¸°
cap = cv2.VideoCapture(0)
hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7)

for manual_label in manual_labels:
    # ìŒììŒ & ì´ì¤‘ëª¨ìŒ ì²´í¬
    if manual_label in double_consonants:
        gesture_components = double_consonants[manual_label]
    elif manual_label in double_vowels:
        gesture_components = double_vowels[manual_label]
    else:
        gesture_components = [manual_label]

    sequence = []  # ë¼ë²¨ë‹¹ í•œ ê°œì˜ npy íŒŒì¼ì„ ì €ì¥í•˜ê¸° ìœ„í•´ ì´ˆê¸°í™”

    for component in gesture_components:
        print(f"ğŸ“¸ í˜„ì¬ ì´¬ì˜ ì¤‘: {component} (ì†ì„ ì˜¬ë¦¬ê³  ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”...)")

        component_sequence = []  # ê°œë³„ ì œìŠ¤ì²˜ ë°ì´í„° ì €ì¥

        start_time = time.time()
        while time.time() - start_time < 3:  # 3ì´ˆ ë™ì•ˆ ì´¬ì˜
            ret, frame = cap.read()
            if not ret:
                break

            # BGR â†’ RGB ë³€í™˜
            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            image.flags.writeable = False
            results = hands.process(image)
            image.flags.writeable = True

            # ì† ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
            if results.multi_hand_landmarks:
                for hand_landmarks in results.multi_hand_landmarks:
                    mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

                    # ëœë“œë§ˆí¬ ë°ì´í„° ìˆ˜ì§‘
                    landmarks = []
                    for lm in hand_landmarks.landmark:
                        landmarks.extend([lm.x, lm.y, lm.z])
                    component_sequence.append(landmarks)

            else:
                component_sequence.append([0] * 63)  # ì†ì´ ê°ì§€ë˜ì§€ ì•Šì„ ê²½ìš° 0ìœ¼ë¡œ íŒ¨ë”©

            # í™”ë©´ì— í‘œì‹œ
            cv2.putText(frame, f"Label: {component} (ì¢…ë£Œ: Q)", (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)
            cv2.imshow("Webcam Feed", frame)

            # ì¢…ë£Œí‚¤ (Q ëˆ„ë¥´ë©´ ì¢…ë£Œ)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                cap.release()
                cv2.destroyAllWindows()
                print("ğŸšª í”„ë¡œê·¸ë¨ ì¢…ë£Œ!")
                exit()

        # ì´¬ì˜í•œ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        sequence.extend(component_sequence)

    # ìµœì¢…ì ìœ¼ë¡œ í•œ ê°œì˜ npy íŒŒì¼ë¡œ ì €ì¥
    np.save(os.path.join(dataset_path, f"test_landmarks_{manual_label}.npy"), np.array(sequence))
    np.save(os.path.join(dataset_path, f"test_label_{manual_label}.npy"), np.array([manual_label]))
    print(f"âœ… {manual_label} ë°ì´í„° ì €ì¥ ì™„ë£Œ!")

    # ë‹¤ìŒ ì´¬ì˜ì„ ìœ„í•œ 3ì´ˆ ëŒ€ê¸°
    print("â³ ë‹¤ìŒ ì œìŠ¤ì²˜ë¡œ ì´ë™ ì¤‘... (ì†ì„ ë‚´ë ¸ë‹¤ê°€ ë‹¤ì‹œ ì˜¬ë ¤ì£¼ì„¸ìš”)")
    time.sleep(3)

cap.release()
cv2.destroyAllWindows()
print("ğŸš€ ëª¨ë“  ë°ì´í„° ì €ì¥ ì™„ë£Œ!")
