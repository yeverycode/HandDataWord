import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# âœ… í•œê¸€ í°íŠ¸ ì„¤ì • (Windows í™˜ê²½)
plt.rc('font', family='Malgun Gothic')
plt.rc('axes', unicode_minus=False)

# ğŸ”¹ F1 Score metric ì •ì˜
def metric_F1score(y_true, y_pred):
    TP = tf.reduce_sum(y_true * tf.round(y_pred))
    FP = tf.reduce_sum((1 - y_true) * tf.round(y_pred))
    FN = tf.reduce_sum(y_true * (1 - tf.round(y_pred)))

    precision = TP / (TP + FP + 1e-7)
    recall = TP / (TP + FN + 1e-7)
    F1score = 2 * precision * recall / (precision + recall + 1e-7)
    return F1score

# ğŸ”¹ ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
def load_sign_model(model_path):
    return load_model(model_path, custom_objects={'metric_F1score': metric_F1score})

# ğŸ”¹ ëª¨ë¸ í‰ê°€ í•¨ìˆ˜
def evaluate_model(model, x_val, y_val, actions):
    # ëª¨ë¸ ì…ë ¥ í¬ê¸° í™•ì¸
    print("\n=== ëª¨ë¸ ì…ë ¥ í˜•íƒœ ===")
    print(f"ëª¨ë¸ ê¸°ëŒ€ ì…ë ¥: {model.input_shape}")
    print(f"ë°ì´í„° ì…ë ¥: {x_val.shape}")

    # ì…ë ¥ í¬ê¸° ì¡°ì • (30 í”„ë ˆì„ì„ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸)
    if x_val.shape[1] != 30:
        print(f"âš  ì…ë ¥ í¬ê¸° ì¡°ì •: {x_val.shape} â†’ ({x_val.shape[0]}, 30, {x_val.shape[2]})")
        x_val = x_val[:, :30, :]

    # ì˜ˆì¸¡ ìˆ˜í–‰
    y_pred = model.predict(x_val)

    # ì›-í•« ì¸ì½”ë”©ëœ ê²°ê³¼ë¥¼ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
    y_val_classes = np.argmax(y_val, axis=1)
    y_pred_classes = np.argmax(y_pred, axis=1)

    # Classification Report ìƒì„±
    report = classification_report(y_val_classes, y_pred_classes, target_names=actions, output_dict=True)
    df_report = pd.DataFrame(report).transpose()
    
    print("\n=== Classification Report ===")
    print(df_report.round(3))

    # Confusion Matrix ì‹œê°í™”
    cm = confusion_matrix(y_val_classes, y_pred_classes)
    plt.figure(figsize=(12, 10))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=actions, yticklabels=actions)
    plt.title('Confusion Matrix')
    plt.xlabel('ì˜ˆì¸¡ê°’')
    plt.ylabel('ì‹¤ì œê°’')
    plt.xticks(rotation=90)
    plt.yticks(rotation=0)
    plt.tight_layout()
    plt.show()

    return df_report

# ğŸ”¹ íŠ¹ì • í´ë˜ìŠ¤(ë‹¨ì–´)ì˜ ì˜ˆì¸¡ ì„±ëŠ¥ í™•ì¸
def analyze_class_performance(y_val_classes, y_pred_classes, actions, target_word):
    target_index = actions.index(target_word)

    report = classification_report(y_val_classes, y_pred_classes, target_names=actions, output_dict=True)
    print(f"\n=== ì„±ëŠ¥ í™•ì¸: {target_word} ===")
    print(f"Precision: {report[target_word]['precision']:.3f}")
    print(f"Recall: {report[target_word]['recall']:.3f}")
    print(f"F1-score: {report[target_word]['f1-score']:.3f}")
    print(f"Support(ìƒ˜í”Œ ìˆ˜): {report[target_word]['support']}")

    # ì˜¤ë¶„ë¥˜ëœ ê²½ìš° ì°¾ê¸°
    misclassified_samples = [(actions[y_val_classes[i]], actions[y_pred_classes[i]]) for i in range(len(y_val_classes))
                             if y_val_classes[i] == target_index and y_pred_classes[i] != target_index]
    
    if misclassified_samples:
        df_misclassified = pd.DataFrame(misclassified_samples, columns=['ì‹¤ì œ í´ë˜ìŠ¤', 'ì˜ˆì¸¡ í´ë˜ìŠ¤'])
        print("\n=== ì˜¤ë¶„ë¥˜ ìƒ˜í”Œ ===")
        print(df_misclassified)

    # Confusion Matrixì—ì„œ íŠ¹ì • í´ë˜ìŠ¤ ì‹œê°í™”
    cm = confusion_matrix(y_val_classes, y_pred_classes)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm[:, target_index].reshape(-1, 1), annot=True, fmt='d', cmap='Blues',
                yticklabels=actions, xticklabels=[target_word])
    plt.title(f"Confusion Matrix - '{target_word}'")
    plt.ylabel("ì‹¤ì œ í´ë˜ìŠ¤")
    plt.xlabel("ì˜ˆì¸¡ëœ í´ë˜ìŠ¤")
    plt.show()

# ğŸ”¹ ë°ì´í„° ë¡œë“œ ë° í‰ê°€ ì‹¤í–‰
if __name__ == "__main__":
    # âœ… ëª¨ë¸ ë¡œë“œ
    model = load_sign_model('./model/Sign_ED_best.keras')

    # âœ… ë°ì´í„° ë¡œë“œ
    x_val = np.load('./dataset/x_val.npy')
    y_val = np.load('./dataset/y_val.npy')

    # ì œìŠ¤ì²˜ ì •ì˜
    actions = [
        'ì•ˆë…•,ì•ˆë¶€', 'ì‹¤ìˆ˜', 'ì‚´ë‹¤,ì‚¶,ìƒí™œ', 'ì·¨ë¯¸',
        'ì•„ë¹ ,ë¶€,ë¶€ì¹œ,ì•„ë¹„,ì•„ë²„ì§€', 'ê±´ê°•,ê¸°ë ¥,ê°•ê±´í•˜ë‹¤,íŠ¼íŠ¼í•˜ë‹¤', 'ì‰¬ë‹¤,íœ´ê°€,íœ´ê²Œ,íœ´ì‹,íœ´ì–‘',
        'ê³ ëª¨', 'ë‹¤ë‹ˆë‹¤', 'ì£½ë‹¤,ëŒì•„ê°€ë‹¤,ì‚¬ê±°,ì‚¬ë§,ì„œê±°,ìˆ¨ì§€ë‹¤,ì£½ìŒ,ì„ì¢…',
        'ëˆ„ë‚˜,ëˆ„ë‹˜', 'ë‚¨í¸,ë°°ìš°ì,ì„œë°©', 'ì–‘ì¹˜ì§ˆ,ì–‘ì¹˜',
        'ëª¸ì‚´', 'ê²°í˜¼,í˜¼ì¸,í™”í˜¼', 'ë‚¨ë™ìƒ', 'ìƒí•˜ë‹¤,ë‹¤ì¹˜ë‹¤,ë¶€ìƒ,ìƒì²˜,ì†ìƒ', 'ë™ìƒ', 'ëª¨ì(ê´€ê³„)', 'ì‹ ê¸°ë¡'
    ]

    # âœ… ëª¨ë¸ í‰ê°€ ìˆ˜í–‰
    report = evaluate_model(model, x_val, y_val, actions)

    # âœ… íŠ¹ì • ë‹¨ì–´ ë¶„ì„ (ì˜ˆ: 'ì¶•êµ¬,ì°¨ë‹¤')
    analyze_class_performance(np.argmax(y_val, axis=1), np.argmax(model.predict(x_val), axis=1), actions, 'ì¶•êµ¬,ì°¨ë‹¤')
