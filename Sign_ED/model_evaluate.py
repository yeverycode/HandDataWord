import numpy as np
from tensorflow.keras.models import load_model
import tensorflow as tf
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import matplotlib.font_manager as fm

# âœ… í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rc('font', family='Malgun Gothic')  # Windows
plt.rc('axes', unicode_minus=False)

# ğŸ”¹ F1 Score metric ì •ì˜
def metric_F1score(y_true, y_pred):
    TP = tf.reduce_sum(y_true * tf.round(y_pred))
    FP = tf.reduce_sum((1 - y_true) * tf.round(y_pred))
    FN = tf.reduce_sum(y_true * (1 - tf.round(y_pred)))
    precision = TP / (TP + FP + 1e-7)
    recall = TP / (TP + FN + 1e-7)
    F1score = 2 * precision * recall / (precision + recall + 1e-7)
    return F1score

# ğŸ”¹ ëª¨ë¸ í‰ê°€ í•¨ìˆ˜
def evaluate_model(model_path, x_val, y_val, actions):
    # âœ… ë§ˆìŠ¤í‚¹ ë¬¸ì œ í•´ê²° (Numpy ë°°ì—´ ë³€í™˜)
    x_val = np.array(x_val)

    # ëª¨ë¸ ë¡œë“œ
    model = load_model(model_path, custom_objects={'metric_F1score': metric_F1score})
    
    # ëª¨ë¸ ìš”ì•½ ì¶œë ¥
    print("\n=== Model Summary ===")
    model.summary()

    # ëª¨ë¸ ì…ë ¥ í¬ê¸° í™•ì¸
    print("\n=== ëª¨ë¸ ì…ë ¥ í˜•íƒœ ===")
    print(f"ëª¨ë¸ ê¸°ëŒ€ ì…ë ¥: {model.input_shape}")
    print(f"ë°ì´í„° ì…ë ¥: {x_val.shape}")

    # ì…ë ¥ í¬ê¸° ì¡°ì • (ëª¨ë¸ì´ 30ê°œ íƒ€ì„ìŠ¤í…ì„ ê¸°ëŒ€í•˜ëŠ” ê²½ìš°)
    if x_val.shape[1] > 30:
        print(f"âš  ì…ë ¥ í¬ê¸° ì¡°ì •: {x_val.shape} â†’ ({x_val.shape[0]}, 30, {x_val.shape[2]})")
        x_val = x_val[:, :30, :]  # ì²« 30ê°œ íƒ€ì„ìŠ¤í…ë§Œ ì‚¬ìš©

    # ì˜ˆì¸¡ ìˆ˜í–‰
    y_pred = model.predict(x_val)

    # ì›-í•« ì¸ì½”ë”©ëœ ê²°ê³¼ë¥¼ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
    y_val_classes = np.argmax(y_val, axis=1)
    y_pred_classes = np.argmax(y_pred, axis=1)

    # Classification Report ìƒì„±
    report = classification_report(y_val_classes, y_pred_classes, target_names=actions, output_dict=True)

    # DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥
    df_report = pd.DataFrame(report).transpose()
    print("\n=== Classification Report ===")
    print(df_report.round(3))

    # Confusion Matrix ìƒì„± ë° ì‹œê°í™”
    cm = confusion_matrix(y_val_classes, y_pred_classes)
    plt.figure(figsize=(12, 10))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=actions, yticklabels=actions)
    plt.title('Confusion Matrix')
    plt.xlabel('ì˜ˆì¸¡ê°’')
    plt.ylabel('ì‹¤ì œê°’')
    plt.xticks(rotation=90)
    plt.yticks(rotation=0)
    plt.tight_layout()
    plt.show()

    # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„
    class_performance = {}
    for i, action in enumerate(actions):
        mask = (y_val_classes == i)
        class_acc = np.mean(y_pred_classes[mask] == i) if np.sum(mask) > 0 else 0.0
        class_performance[action] = {
            'accuracy': class_acc,
            'samples': np.sum(mask),
            'correct_predictions': np.sum(y_pred_classes[mask] == i)
        }

    # ì„±ëŠ¥ì´ ë‚®ì€ í´ë˜ìŠ¤ ì‹ë³„ (ì˜ˆ: ì •í™•ë„ 95% ë¯¸ë§Œ)
    poor_performing = {k: v for k, v in class_performance.items() if v['accuracy'] < 0.95}

    if poor_performing:
        print("\n=== ì„±ëŠ¥ì´ ë‚®ì€ í´ë˜ìŠ¤ ===")
        for action, stats in poor_performing.items():
            print(f"{action}:")
            print(f"  ì •í™•ë„: {stats['accuracy']*100:.2f}%")
            print(f"  ìƒ˜í”Œ ìˆ˜: {stats['samples']}")
            print(f"  ì •í™•í•œ ì˜ˆì¸¡: {stats['correct_predictions']}")

    # ì „ì²´ ëª¨ë¸ ì„±ëŠ¥ ë©”íŠ¸ë¦­
    test_loss, test_acc = model.evaluate(x_val, y_val, verbose=0)
    print("\n=== ì „ì²´ ëª¨ë¸ ì„±ëŠ¥ ===")
    print(f"Test Accuracy: {test_acc*100:.2f}%")
    print(f"Test Loss: {test_loss:.4f}")

    return df_report, class_performance

# ğŸ”¹ ë°ì´í„° ë¡œë“œ ë° í‰ê°€ ì‹¤í–‰
if __name__ == "__main__":
    # ì œê³µëœ ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°
    x_val = np.load('./dataset/x_val.npy')
    y_val = np.load('./dataset/y_val.npy')

# ì œìŠ¤ì²˜ ì •ì˜
    actions = [
        'ì•ˆë…•,ì•ˆë¶€', 'ì‹¤ìˆ˜', 'ì‚´ë‹¤,ì‚¶,ìƒí™œ', 'ì·¨ë¯¸',
        'ì•„ë¹ ,ë¶€,ë¶€ì¹œ,ì•„ë¹„,ì•„ë²„ì§€', 'ê±´ê°•,ê¸°ë ¥,ê°•ê±´í•˜ë‹¤,íŠ¼íŠ¼í•˜ë‹¤', 'ì‰¬ë‹¤,íœ´ê°€,íœ´ê²Œ,íœ´ì‹,íœ´ì–‘',
        'ê³ ëª¨', 'ë‹¤ë‹ˆë‹¤', 'ì£½ë‹¤,ëŒì•„ê°€ë‹¤,ì‚¬ê±°,ì‚¬ë§,ì„œê±°,ìˆ¨ì§€ë‹¤,ì£½ìŒ,ì„ì¢…', 'ë‚¨í¸,ë°°ìš°ì,ì„œë°©',
        'ëª¸ì‚´', 'ê²°í˜¼,í˜¼ì¸,í™”í˜¼', 'ë…¸ë˜,ìŒì•…,ê°€ìš”', 'ë™ìƒ', 'ëª¨ì(ê´€ê³„)', 'ì‹ ê¸°ë¡'
    ]
    # ëª¨ë¸ í‰ê°€ í•¨ìˆ˜ ì‹¤í–‰
    report, performance = evaluate_model('./model/Sign_ED_best.keras', x_val, y_val, actions)
